{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle TensorFlow Speech Competition\n",
    "Use TensorFlow Simple Audio Recognition tutorial code to create submitssion file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/data\n"
     ]
    }
   ],
   "source": [
    "# download dataset\n",
    "import os, sys\n",
    "\n",
    "NOTEBOOK_DIR = '/notebooks'\n",
    "DATA_DIR = '/notebooks/data'\n",
    "TRAIN_DIR = DATA_DIR + '/training_atom'\n",
    "TEST_DIR = DATA_DIR + \"/test/audio\"\n",
    "KAGGLE_TRAIN_DATA_DIR = DATA_DIR + '/train/audio'\n",
    "\n",
    "if os.path.isdir(DATA_DIR):\n",
    "    os.chdir(DATA_DIR)\n",
    "else:\n",
    "    os.chdir(NOTEBOOK_DIR)\n",
    "    os.mkdir('data')\n",
    "    os.chdir('data')\n",
    "\n",
    "print (os.getcwd())\n",
    "\n",
    "# Allow relative imports to directories above lesson1/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "# assume that the data is downloaded and extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select some files as samples\n",
    "#os.mkdir('sample/train')\n",
    "#os.mkdir('sample/valid')\n",
    "#os.mkdir('sample/result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try speech_command sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "import tensorflow as tf\n",
    "\n",
    "import input_data; reload (input_data)\n",
    "import models\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# Set up argument list\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_url', type=str,\n",
    "                    # pylint: disable=line-too-long\n",
    "                    #default='http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz',\n",
    "                    default='',\n",
    "                    # pylint: enable=line-too-long\n",
    "                    help='Location of speech training data archive on the web.')\n",
    "parser.add_argument('--data_dir', type=str, default=KAGGLE_TRAIN_DATA_DIR,\n",
    "                    help=\"\"\"\\\n",
    "                    Where to download the speech training data to.\n",
    "                    \"\"\")\n",
    "parser.add_argument('--background_volume', type=float, default=0.1,\n",
    "                    help=\"\"\"\\\n",
    "                    How loud the background noise should be, between 0 and 1.\n",
    "                    \"\"\")\n",
    "parser.add_argument('--background_frequency', type=float, default=0.8,\n",
    "                    help=\"\"\"\\\n",
    "                    How many of the training samples have background noise mixed in.\n",
    "                    \"\"\")\n",
    "parser.add_argument('--silence_percentage', type=float, default=10.0,\n",
    "                    help=\"\"\"\\\n",
    "                    How much of the training data should be silence.\n",
    "                    \"\"\")\n",
    "parser.add_argument('--unknown_percentage', type=float, default=10.0,\n",
    "                    help=\"\"\"\\\n",
    "                    How much of the training data should be unknown words.\n",
    "                    \"\"\")\n",
    "parser.add_argument('--time_shift_ms', type=float, default=100.0,\n",
    "                    help=\"\"\"\\\n",
    "                    Range to randomly shift the training audio by in time.\n",
    "                    \"\"\")\n",
    "parser.add_argument('--testing_percentage', type=int, default=10,\n",
    "                    help='What percentage of wavs to use as a test set.')\n",
    "parser.add_argument('--validation_percentage', type=int, default=10,\n",
    "                    help='What percentage of wavs to use as a validation set.')\n",
    "parser.add_argument('--sample_rate', type=int, default=16000,\n",
    "                    help='Expected sample rate of the wavs',)\n",
    "parser.add_argument('--clip_duration_ms', type=int, default=1000,\n",
    "                    help='Expected duration in milliseconds of the wavs',)\n",
    "parser.add_argument('--window_size_ms', type=float, default=30.0,\n",
    "                    help='How long each spectrogram timeslice is',)\n",
    "parser.add_argument('--window_stride_ms', type=float, default=10.0,\n",
    "                    help='How long each spectrogram timeslice is',)\n",
    "parser.add_argument('--dct_coefficient_count', type=int, default=40,\n",
    "                    help='How many bins to use for the MFCC fingerprint',)\n",
    "# default='15000,3000',\n",
    "parser.add_argument('--how_many_training_steps', type=str, default='1800,600,2000',\n",
    "                    help='How many training loops to run',)\n",
    "parser.add_argument('--eval_step_interval', type=int, default=400,\n",
    "                    help='How often to evaluate the training results.')\n",
    "parser.add_argument('--learning_rate', type=str, default='0.001,0.0001,0.00001',\n",
    "                    help='How large a learning rate to use when training.')\n",
    "parser.add_argument('--batch_size', type=int, default=100,\n",
    "                    help='How many items to train with at once',)\n",
    "parser.add_argument('--summaries_dir', type=str, default=TRAIN_DIR + '/retrain_logs',\n",
    "                    help='Where to save summary logs for TensorBoard.')\n",
    "parser.add_argument('--wanted_words', type=str, default='yes,no,up,down,left,right,on,off,stop,go',\n",
    "                    help='Words to use (others will be added to an unknown label)',)\n",
    "parser.add_argument('--train_dir', type=str, default=TRAIN_DIR + '/speech_commands_train',\n",
    "                    help='Directory to write event logs and checkpoint.')\n",
    "parser.add_argument('--save_step_interval', type=int, default=100,\n",
    "                    help='Save model checkpoint every save_steps.')\n",
    "#--start_checkpoint=/tmp/speech_commands_train/conv.ckpt-100 or TRAIN_DIR + '/speech_commands_train/conv.ckpt-2400'\n",
    "parser.add_argument('--start_checkpoint', type=str, default=TRAIN_DIR + '/speech_commands_train/conv.ckpt-2900',\n",
    "                    help='If specified, restore this pretrained model before any training.')\n",
    "parser.add_argument('--model_architecture', type=str, default='conv',\n",
    "                    help='What model architecture to use')\n",
    "parser.add_argument('--check_nans', type=bool, default=False,\n",
    "                    help='Whether to check for invalid numbers during processing')\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words to work with :\n",
      "{'sheila': True, 'seven': True, 'right': True, 'house': True, 'up': True, 'down': True, 'zero': True, 'go': True, 'yes': True, 'no': True, 'wow': True, 'six': True, 'two': True, 'bird': True, 'happy': True, 'marvin': True, 'stop': True, 'five': True, 'one': True, 'on': True, 'off': True, 'four': True, 'tree': True, 'dog': True, 'bed': True, 'cat': True, 'nine': True, 'three': True, 'eight': True, 'left': True}\n",
      "Words in interest :\n",
      "['_silence_', '_unknown_', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Start a new TensorFlow session.\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Begin by making sure we have the training data we need. If you already have\n",
    "# training data of your own, use `--data_url= ` on the command line to avoid\n",
    "# downloading.\n",
    "model_settings = models.prepare_model_settings(\n",
    "    len(input_data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "    FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "    FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "audio_processor = input_data.AudioProcessor(\n",
    "    FLAGS.data_url, FLAGS.data_dir, FLAGS.silence_percentage,\n",
    "    FLAGS.unknown_percentage,\n",
    "    FLAGS.wanted_words.split(','), FLAGS.validation_percentage,\n",
    "    FLAGS.testing_percentage, model_settings)\n",
    "fingerprint_size = model_settings['fingerprint_size']\n",
    "label_count = model_settings['label_count']\n",
    "time_shift_samples = int((FLAGS.time_shift_ms * FLAGS.sample_rate) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fingerprint_size': 3920, 'dct_coefficient_count': 40, 'sample_rate': 16000, 'window_size_samples': 480, 'spectrogram_length': 98, 'desired_samples': 16000, 'window_stride_samples': 160, 'label_count': 12}\n",
      "<input_data.AudioProcessor object at 0x7f36c58c4350>\n",
      "3920\n",
      "12\n",
      "1600\n",
      "['_silence_', '_unknown_', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n"
     ]
    }
   ],
   "source": [
    "print (model_settings)\n",
    "print (audio_processor)\n",
    "print (fingerprint_size)\n",
    "print (label_count)\n",
    "print (time_shift_samples)\n",
    "print (input_data.prepare_words_list(FLAGS.wanted_words.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out the learning rates for each training phase. Since it's often\n",
    "# effective to have high learning rates at the start of training, followed by\n",
    "# lower levels towards the end, the number of steps and learning rates can be\n",
    "# specified as comma-separated lists to define the rate at each stage. For\n",
    "# example --how_many_training_steps=10000,3000 --learning_rate=0.001,0.0001\n",
    "# will run 13,000 training loops in total, with a rate of 0.001 for the first\n",
    "# 10,000, and 0.0001 for the final 3,000.\n",
    "training_steps_list = list(map(int, FLAGS.how_many_training_steps.split(',')))\n",
    "learning_rates_list = list(map(float, FLAGS.learning_rate.split(',')))\n",
    "if len(training_steps_list) != len(learning_rates_list):\n",
    "    raise Exception(\n",
    "        '--how_many_training_steps and --learning_rate must be equal length '\n",
    "        'lists, but are %d and %d long instead' % (len(training_steps_list),\n",
    "                                                   len(learning_rates_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800, 600, 2000]\n",
      "[0.001, 0.0001, 1e-05]\n",
      "conv\n"
     ]
    }
   ],
   "source": [
    "print (training_steps_list)\n",
    "print (learning_rates_list)\n",
    "print (FLAGS.model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fingerprint_input = tf.placeholder(tf.float32, [None, fingerprint_size], name='fingerprint_input')\n",
    "logits, dropout_prob = models.create_model(fingerprint_input, model_settings,\n",
    "                                           FLAGS.model_architecture, is_training=True)\n",
    "# Define loss and optimizer\n",
    "ground_truth_input = tf.placeholder(tf.float32, [None, label_count], name='groundtruth_input')\n",
    "\n",
    "# Optionally we can add runtime checks to spot when NaNs or other symptoms of\n",
    "# numerical errors start occurring during training.\n",
    "control_dependencies = []\n",
    "if FLAGS.check_nans:\n",
    "    checks = tf.add_check_numerics_ops()\n",
    "    control_dependencies = [checks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the back propagation and training evaluation machinery in the graph.\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy_mean = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels=ground_truth_input, logits=logits))\n",
    "tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "    \n",
    "with tf.name_scope('train'), tf.control_dependencies(control_dependencies):\n",
    "    learning_rate_input = tf.placeholder(\n",
    "        tf.float32, [], name='learning_rate_input')\n",
    "    train_step = tf.train.AdamOptimizer(\n",
    "        learning_rate_input).minimize(cross_entropy_mean)\n",
    "    \n",
    "predicted_indices = tf.argmax(logits, 1)\n",
    "expected_indices = tf.argmax(ground_truth_input, 1)\n",
    "correct_prediction = tf.equal(predicted_indices, expected_indices)\n",
    "confusion_matrix = tf.confusion_matrix(expected_indices, predicted_indices)\n",
    "evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "tf.summary.scalar('accuracy', evaluation_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-7b70b77dca57>:1: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n"
     ]
    }
   ],
   "source": [
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "increment_global_step = tf.assign(global_step, global_step + 1)\n",
    "\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# Merge all the summaries and write them out to /tmp/retrain_logs (by default)\n",
    "merged_summaries = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\n",
    "                                   sess.graph)\n",
    "validation_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /notebooks/data/training_atom/speech_commands_train/conv.ckpt-2900\n",
      "INFO:tensorflow:Training from step: 2901 \n",
      "Word list : \n",
      "['_silence_', '_unknown_', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n"
     ]
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "\n",
    "start_step = 1\n",
    "\n",
    "if FLAGS.start_checkpoint:\n",
    "    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\n",
    "    start_step = global_step.eval(session=sess)\n",
    "\n",
    "tf.logging.info('Training from step: %d ', start_step)\n",
    "\n",
    "# Save graph.pbtxt.\n",
    "tf.train.write_graph(sess.graph_def, FLAGS.train_dir,\n",
    "                     FLAGS.model_architecture + '.pbtxt')\n",
    "\n",
    "# Save list of words.\n",
    "with gfile.GFile(\n",
    "    os.path.join(FLAGS.train_dir, FLAGS.model_architecture + '_labels.txt'),\n",
    "    'w') as f:\n",
    "    f.write('\\n'.join(audio_processor.words_list)+'\\n')\n",
    "    \n",
    "print (\"Word list : \")\n",
    "print (audio_processor.words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #2910: rate 0.000010, accuracy 87.0%, cross entropy 0.368795\n",
      "INFO:tensorflow:Step #2920: rate 0.000010, accuracy 87.0%, cross entropy 0.484192\n",
      "INFO:tensorflow:Step #2930: rate 0.000010, accuracy 89.0%, cross entropy 0.396397\n",
      "INFO:tensorflow:Step #2940: rate 0.000010, accuracy 87.0%, cross entropy 0.321800\n",
      "INFO:tensorflow:Step #2950: rate 0.000010, accuracy 91.0%, cross entropy 0.498677\n",
      "INFO:tensorflow:Step #2960: rate 0.000010, accuracy 83.0%, cross entropy 0.436577\n",
      "INFO:tensorflow:Step #2970: rate 0.000010, accuracy 82.0%, cross entropy 0.582912\n",
      "INFO:tensorflow:Step #2980: rate 0.000010, accuracy 86.0%, cross entropy 0.537272\n",
      "INFO:tensorflow:Step #2990: rate 0.000010, accuracy 84.0%, cross entropy 0.413963\n",
      "INFO:tensorflow:Step #3000: rate 0.000010, accuracy 88.0%, cross entropy 0.479693\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3000\"\n",
      "INFO:tensorflow:Step #3010: rate 0.000010, accuracy 84.0%, cross entropy 0.545643\n",
      "INFO:tensorflow:Step #3020: rate 0.000010, accuracy 85.0%, cross entropy 0.514878\n",
      "INFO:tensorflow:Step #3030: rate 0.000010, accuracy 90.0%, cross entropy 0.374837\n",
      "INFO:tensorflow:Step #3040: rate 0.000010, accuracy 91.0%, cross entropy 0.314711\n",
      "INFO:tensorflow:Step #3050: rate 0.000010, accuracy 84.0%, cross entropy 0.604676\n",
      "INFO:tensorflow:Step #3060: rate 0.000010, accuracy 84.0%, cross entropy 0.519812\n",
      "INFO:tensorflow:Step #3070: rate 0.000010, accuracy 86.0%, cross entropy 0.407347\n",
      "INFO:tensorflow:Step #3080: rate 0.000010, accuracy 83.0%, cross entropy 0.633993\n",
      "INFO:tensorflow:Step #3090: rate 0.000010, accuracy 78.0%, cross entropy 0.636507\n",
      "INFO:tensorflow:Step #3100: rate 0.000010, accuracy 88.0%, cross entropy 0.426287\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3100\"\n",
      "INFO:tensorflow:Step #3110: rate 0.000010, accuracy 81.0%, cross entropy 0.605789\n",
      "INFO:tensorflow:Step #3120: rate 0.000010, accuracy 82.0%, cross entropy 0.454923\n",
      "INFO:tensorflow:Step #3130: rate 0.000010, accuracy 92.0%, cross entropy 0.384905\n",
      "INFO:tensorflow:Step #3140: rate 0.000010, accuracy 84.0%, cross entropy 0.487121\n",
      "INFO:tensorflow:Step #3150: rate 0.000010, accuracy 85.0%, cross entropy 0.502746\n",
      "INFO:tensorflow:Step #3160: rate 0.000010, accuracy 85.0%, cross entropy 0.478010\n",
      "INFO:tensorflow:Step #3170: rate 0.000010, accuracy 85.0%, cross entropy 0.518950\n",
      "INFO:tensorflow:Step #3180: rate 0.000010, accuracy 83.0%, cross entropy 0.478825\n",
      "INFO:tensorflow:Step #3190: rate 0.000010, accuracy 83.0%, cross entropy 0.442774\n",
      "INFO:tensorflow:Step #3200: rate 0.000010, accuracy 86.0%, cross entropy 0.537152\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[258   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2 177   5   3   5  11   7  12  14   6   4  12]\n",
      " [  3   1 246   3   0   1   7   0   0   0   0   0]\n",
      " [  2   8   1 236   2   4   1   0   0   0   2  14]\n",
      " [  5   3   0   1 237   0   3   1   0   8   2   0]\n",
      " [  0   5   1  21   1 224   2   0   0   1   4   5]\n",
      " [  1   3  15   3   1   0 219   4   1   0   0   0]\n",
      " [  1   8   0   1   0   1   2 243   0   0   0   0]\n",
      " [  5   5   0   0   2   2   0   2 233   7   1   0]\n",
      " [  2   2   0   0  29   0   2   1   3 215   1   1]\n",
      " [  3   1   1   1  12   3   3   0   0   2 219   1]\n",
      " [  7   8   0  15   4   7   1   0   2   3   2 211]]\n",
      "INFO:tensorflow:Step 3200: Validation accuracy = 87.9% (N=3093)\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3200\"\n",
      "INFO:tensorflow:Step #3210: rate 0.000010, accuracy 89.0%, cross entropy 0.594632\n",
      "INFO:tensorflow:Step #3220: rate 0.000010, accuracy 84.0%, cross entropy 0.450274\n",
      "INFO:tensorflow:Step #3230: rate 0.000010, accuracy 84.0%, cross entropy 0.515840\n",
      "INFO:tensorflow:Step #3240: rate 0.000010, accuracy 85.0%, cross entropy 0.568175\n",
      "INFO:tensorflow:Step #3250: rate 0.000010, accuracy 85.0%, cross entropy 0.505937\n",
      "INFO:tensorflow:Step #3260: rate 0.000010, accuracy 85.0%, cross entropy 0.650876\n",
      "INFO:tensorflow:Step #3270: rate 0.000010, accuracy 83.0%, cross entropy 0.467834\n",
      "INFO:tensorflow:Step #3280: rate 0.000010, accuracy 83.0%, cross entropy 0.634125\n",
      "INFO:tensorflow:Step #3290: rate 0.000010, accuracy 89.0%, cross entropy 0.463402\n",
      "INFO:tensorflow:Step #3300: rate 0.000010, accuracy 83.0%, cross entropy 0.537426\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3300\"\n",
      "INFO:tensorflow:Step #3310: rate 0.000010, accuracy 88.0%, cross entropy 0.396610\n",
      "INFO:tensorflow:Step #3320: rate 0.000010, accuracy 88.0%, cross entropy 0.372491\n",
      "INFO:tensorflow:Step #3330: rate 0.000010, accuracy 80.0%, cross entropy 0.653110\n",
      "INFO:tensorflow:Step #3340: rate 0.000010, accuracy 84.0%, cross entropy 0.462355\n",
      "INFO:tensorflow:Step #3350: rate 0.000010, accuracy 87.0%, cross entropy 0.400218\n",
      "INFO:tensorflow:Step #3360: rate 0.000010, accuracy 89.0%, cross entropy 0.435495\n",
      "INFO:tensorflow:Step #3370: rate 0.000010, accuracy 81.0%, cross entropy 0.460827\n",
      "INFO:tensorflow:Step #3380: rate 0.000010, accuracy 87.0%, cross entropy 0.480876\n",
      "INFO:tensorflow:Step #3390: rate 0.000010, accuracy 82.0%, cross entropy 0.503227\n",
      "INFO:tensorflow:Step #3400: rate 0.000010, accuracy 81.0%, cross entropy 0.491905\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3400\"\n",
      "INFO:tensorflow:Step #3410: rate 0.000010, accuracy 87.0%, cross entropy 0.405873\n",
      "INFO:tensorflow:Step #3420: rate 0.000010, accuracy 87.0%, cross entropy 0.460964\n",
      "INFO:tensorflow:Step #3430: rate 0.000010, accuracy 84.0%, cross entropy 0.505105\n",
      "INFO:tensorflow:Step #3440: rate 0.000010, accuracy 93.0%, cross entropy 0.265063\n",
      "INFO:tensorflow:Step #3450: rate 0.000010, accuracy 84.0%, cross entropy 0.602722\n",
      "INFO:tensorflow:Step #3460: rate 0.000010, accuracy 89.0%, cross entropy 0.353405\n",
      "INFO:tensorflow:Step #3470: rate 0.000010, accuracy 85.0%, cross entropy 0.521403\n",
      "INFO:tensorflow:Step #3480: rate 0.000010, accuracy 86.0%, cross entropy 0.451701\n",
      "INFO:tensorflow:Step #3490: rate 0.000010, accuracy 88.0%, cross entropy 0.534736\n",
      "INFO:tensorflow:Step #3500: rate 0.000010, accuracy 87.0%, cross entropy 0.475526\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3500\"\n",
      "INFO:tensorflow:Step #3510: rate 0.000010, accuracy 87.0%, cross entropy 0.469325\n",
      "INFO:tensorflow:Step #3520: rate 0.000010, accuracy 79.0%, cross entropy 0.767232\n",
      "INFO:tensorflow:Step #3530: rate 0.000010, accuracy 82.0%, cross entropy 0.534687\n",
      "INFO:tensorflow:Step #3540: rate 0.000010, accuracy 88.0%, cross entropy 0.441374\n",
      "INFO:tensorflow:Step #3550: rate 0.000010, accuracy 85.0%, cross entropy 0.563243\n",
      "INFO:tensorflow:Step #3560: rate 0.000010, accuracy 89.0%, cross entropy 0.440023\n",
      "INFO:tensorflow:Step #3570: rate 0.000010, accuracy 80.0%, cross entropy 0.579809\n",
      "INFO:tensorflow:Step #3580: rate 0.000010, accuracy 82.0%, cross entropy 0.503807\n",
      "INFO:tensorflow:Step #3590: rate 0.000010, accuracy 85.0%, cross entropy 0.580037\n",
      "INFO:tensorflow:Step #3600: rate 0.000010, accuracy 84.0%, cross entropy 0.482399\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[258   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2 173   4   2   7  14   5  13  15   6   4  13]\n",
      " [  3   2 245   3   0   1   7   0   0   0   0   0]\n",
      " [  2  10   1 233   2   4   0   0   0   0   1  17]\n",
      " [  4   5   0   1 238   0   2   1   0   8   1   0]\n",
      " [  0   6   1  21   1 224   2   0   0   1   3   5]\n",
      " [  1   4  15   3   1   0 218   4   1   0   0   0]\n",
      " [  1  12   0   0   0   0   1 242   0   0   0   0]\n",
      " [  5   7   0   0   2   2   0   2 232   6   1   0]\n",
      " [  2   2   0   0  26   0   2   1   3 218   1   1]\n",
      " [  3   4   1   0  14   2   2   0   0   2 216   2]\n",
      " [  7   7   0  13   6   6   1   0   2   3   1 214]]\n",
      "INFO:tensorflow:Step 3600: Validation accuracy = 87.6% (N=3093)\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3600\"\n",
      "INFO:tensorflow:Step #3610: rate 0.000010, accuracy 87.0%, cross entropy 0.431994\n",
      "INFO:tensorflow:Step #3620: rate 0.000010, accuracy 87.0%, cross entropy 0.390338\n",
      "INFO:tensorflow:Step #3630: rate 0.000010, accuracy 88.0%, cross entropy 0.341522\n",
      "INFO:tensorflow:Step #3640: rate 0.000010, accuracy 80.0%, cross entropy 0.602817\n",
      "INFO:tensorflow:Step #3650: rate 0.000010, accuracy 89.0%, cross entropy 0.386298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Step #3660: rate 0.000010, accuracy 81.0%, cross entropy 0.556565\n",
      "INFO:tensorflow:Step #3670: rate 0.000010, accuracy 87.0%, cross entropy 0.446077\n",
      "INFO:tensorflow:Step #3680: rate 0.000010, accuracy 81.0%, cross entropy 0.524547\n",
      "INFO:tensorflow:Step #3690: rate 0.000010, accuracy 86.0%, cross entropy 0.520552\n",
      "INFO:tensorflow:Step #3700: rate 0.000010, accuracy 85.0%, cross entropy 0.628539\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3700\"\n",
      "INFO:tensorflow:Step #3710: rate 0.000010, accuracy 86.0%, cross entropy 0.438567\n",
      "INFO:tensorflow:Step #3720: rate 0.000010, accuracy 88.0%, cross entropy 0.422432\n",
      "INFO:tensorflow:Step #3730: rate 0.000010, accuracy 85.0%, cross entropy 0.377122\n",
      "INFO:tensorflow:Step #3740: rate 0.000010, accuracy 87.0%, cross entropy 0.416271\n",
      "INFO:tensorflow:Step #3750: rate 0.000010, accuracy 87.0%, cross entropy 0.472930\n",
      "INFO:tensorflow:Step #3760: rate 0.000010, accuracy 85.0%, cross entropy 0.484890\n",
      "INFO:tensorflow:Step #3770: rate 0.000010, accuracy 87.0%, cross entropy 0.390650\n",
      "INFO:tensorflow:Step #3780: rate 0.000010, accuracy 89.0%, cross entropy 0.448672\n",
      "INFO:tensorflow:Step #3790: rate 0.000010, accuracy 83.0%, cross entropy 0.519388\n",
      "INFO:tensorflow:Step #3800: rate 0.000010, accuracy 89.0%, cross entropy 0.412029\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3800\"\n",
      "INFO:tensorflow:Step #3810: rate 0.000010, accuracy 83.0%, cross entropy 0.587214\n",
      "INFO:tensorflow:Step #3820: rate 0.000010, accuracy 91.0%, cross entropy 0.369846\n",
      "INFO:tensorflow:Step #3830: rate 0.000010, accuracy 82.0%, cross entropy 0.602485\n",
      "INFO:tensorflow:Step #3840: rate 0.000010, accuracy 90.0%, cross entropy 0.347652\n",
      "INFO:tensorflow:Step #3850: rate 0.000010, accuracy 86.0%, cross entropy 0.452760\n",
      "INFO:tensorflow:Step #3860: rate 0.000010, accuracy 90.0%, cross entropy 0.400590\n",
      "INFO:tensorflow:Step #3870: rate 0.000010, accuracy 82.0%, cross entropy 0.471775\n",
      "INFO:tensorflow:Step #3880: rate 0.000010, accuracy 82.0%, cross entropy 0.569645\n",
      "INFO:tensorflow:Step #3890: rate 0.000010, accuracy 86.0%, cross entropy 0.422357\n",
      "INFO:tensorflow:Step #3900: rate 0.000010, accuracy 80.0%, cross entropy 0.643739\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-3900\"\n",
      "INFO:tensorflow:Step #3910: rate 0.000010, accuracy 87.0%, cross entropy 0.374769\n",
      "INFO:tensorflow:Step #3920: rate 0.000010, accuracy 81.0%, cross entropy 0.533074\n",
      "INFO:tensorflow:Step #3930: rate 0.000010, accuracy 87.0%, cross entropy 0.446613\n",
      "INFO:tensorflow:Step #3940: rate 0.000010, accuracy 90.0%, cross entropy 0.254618\n",
      "INFO:tensorflow:Step #3950: rate 0.000010, accuracy 91.0%, cross entropy 0.290025\n",
      "INFO:tensorflow:Step #3960: rate 0.000010, accuracy 81.0%, cross entropy 0.471839\n",
      "INFO:tensorflow:Step #3970: rate 0.000010, accuracy 90.0%, cross entropy 0.417336\n",
      "INFO:tensorflow:Step #3980: rate 0.000010, accuracy 89.0%, cross entropy 0.390101\n",
      "INFO:tensorflow:Step #3990: rate 0.000010, accuracy 85.0%, cross entropy 0.471611\n",
      "INFO:tensorflow:Step #4000: rate 0.000010, accuracy 84.0%, cross entropy 0.445405\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[258   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2 175   5   3   7  14   7  10  14   5   4  12]\n",
      " [  3   1 247   3   0   1   6   0   0   0   0   0]\n",
      " [  2   4   1 240   2   4   1   0   0   0   1  15]\n",
      " [  5   4   0   1 237   0   2   1   0   8   2   0]\n",
      " [  0   5   1  22   1 224   2   0   0   1   4   4]\n",
      " [  1   2  18   3   1   0 218   3   1   0   0   0]\n",
      " [  1  10   0   1   0   1   2 241   0   0   0   0]\n",
      " [  5   4   0   0   2   2   0   2 233   8   1   0]\n",
      " [  2   2   0   0  31   0   2   1   3 214   0   1]\n",
      " [  3   1   1   2  13   3   3   0   0   2 218   0]\n",
      " [  7   7   0  16   4   8   1   0   2   3   2 210]]\n",
      "INFO:tensorflow:Step 4000: Validation accuracy = 87.8% (N=3093)\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-4000\"\n",
      "INFO:tensorflow:Step #4010: rate 0.000010, accuracy 86.0%, cross entropy 0.430227\n",
      "INFO:tensorflow:Step #4020: rate 0.000010, accuracy 80.0%, cross entropy 0.564198\n",
      "INFO:tensorflow:Step #4030: rate 0.000010, accuracy 90.0%, cross entropy 0.315685\n",
      "INFO:tensorflow:Step #4040: rate 0.000010, accuracy 87.0%, cross entropy 0.532039\n",
      "INFO:tensorflow:Step #4050: rate 0.000010, accuracy 88.0%, cross entropy 0.393203\n",
      "INFO:tensorflow:Step #4060: rate 0.000010, accuracy 82.0%, cross entropy 0.684095\n",
      "INFO:tensorflow:Step #4070: rate 0.000010, accuracy 88.0%, cross entropy 0.303003\n",
      "INFO:tensorflow:Step #4080: rate 0.000010, accuracy 85.0%, cross entropy 0.419930\n",
      "INFO:tensorflow:Step #4090: rate 0.000010, accuracy 88.0%, cross entropy 0.624529\n",
      "INFO:tensorflow:Step #4100: rate 0.000010, accuracy 76.0%, cross entropy 0.594846\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-4100\"\n",
      "INFO:tensorflow:Step #4110: rate 0.000010, accuracy 89.0%, cross entropy 0.358590\n",
      "INFO:tensorflow:Step #4120: rate 0.000010, accuracy 80.0%, cross entropy 0.605987\n",
      "INFO:tensorflow:Step #4130: rate 0.000010, accuracy 91.0%, cross entropy 0.402366\n",
      "INFO:tensorflow:Step #4140: rate 0.000010, accuracy 78.0%, cross entropy 0.626588\n",
      "INFO:tensorflow:Step #4150: rate 0.000010, accuracy 86.0%, cross entropy 0.432542\n",
      "INFO:tensorflow:Step #4160: rate 0.000010, accuracy 88.0%, cross entropy 0.435643\n",
      "INFO:tensorflow:Step #4170: rate 0.000010, accuracy 86.0%, cross entropy 0.480408\n",
      "INFO:tensorflow:Step #4180: rate 0.000010, accuracy 87.0%, cross entropy 0.592007\n",
      "INFO:tensorflow:Step #4190: rate 0.000010, accuracy 84.0%, cross entropy 0.541880\n",
      "INFO:tensorflow:Step #4200: rate 0.000010, accuracy 88.0%, cross entropy 0.420148\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-4200\"\n",
      "INFO:tensorflow:Step #4210: rate 0.000010, accuracy 81.0%, cross entropy 0.547868\n",
      "INFO:tensorflow:Step #4220: rate 0.000010, accuracy 92.0%, cross entropy 0.417887\n",
      "INFO:tensorflow:Step #4230: rate 0.000010, accuracy 77.0%, cross entropy 0.755732\n",
      "INFO:tensorflow:Step #4240: rate 0.000010, accuracy 83.0%, cross entropy 0.480970\n",
      "INFO:tensorflow:Step #4250: rate 0.000010, accuracy 80.0%, cross entropy 0.753623\n",
      "INFO:tensorflow:Step #4260: rate 0.000010, accuracy 89.0%, cross entropy 0.350613\n",
      "INFO:tensorflow:Step #4270: rate 0.000010, accuracy 90.0%, cross entropy 0.460603\n",
      "INFO:tensorflow:Step #4280: rate 0.000010, accuracy 81.0%, cross entropy 0.518198\n",
      "INFO:tensorflow:Step #4290: rate 0.000010, accuracy 85.0%, cross entropy 0.465015\n",
      "INFO:tensorflow:Step #4300: rate 0.000010, accuracy 85.0%, cross entropy 0.764061\n",
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-4300\"\n",
      "INFO:tensorflow:Step #4310: rate 0.000010, accuracy 84.0%, cross entropy 0.517058\n",
      "INFO:tensorflow:Step #4320: rate 0.000010, accuracy 89.0%, cross entropy 0.468741\n",
      "INFO:tensorflow:Step #4330: rate 0.000010, accuracy 83.0%, cross entropy 0.571645\n",
      "INFO:tensorflow:Step #4340: rate 0.000010, accuracy 88.0%, cross entropy 0.461611\n",
      "INFO:tensorflow:Step #4350: rate 0.000010, accuracy 90.0%, cross entropy 0.306029\n",
      "INFO:tensorflow:Step #4360: rate 0.000010, accuracy 92.0%, cross entropy 0.282945\n",
      "INFO:tensorflow:Step #4370: rate 0.000010, accuracy 81.0%, cross entropy 0.594248\n",
      "INFO:tensorflow:Step #4380: rate 0.000010, accuracy 85.0%, cross entropy 0.467908\n",
      "INFO:tensorflow:Step #4390: rate 0.000010, accuracy 83.0%, cross entropy 0.473706\n",
      "INFO:tensorflow:Step #4400: rate 0.000010, accuracy 87.0%, cross entropy 0.395025\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[258   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2 178   5   2   6  13   6  11  13   5   4  13]\n",
      " [  3   1 247   3   0   1   6   0   0   0   0   0]\n",
      " [  2   9   1 234   2   4   1   0   0   0   1  16]\n",
      " [  5   3   0   1 238   0   3   1   0   8   1   0]\n",
      " [  0   6   1  20   1 225   2   0   0   1   3   5]\n",
      " [  1   2  18   3   1   0 217   3   1   1   0   0]\n",
      " [  1   9   0   1   0   1   1 243   0   0   0   0]\n",
      " [  5   5   0   0   2   2   0   2 234   6   1   0]\n",
      " [  2   2   0   0  31   0   2   1   3 214   0   1]\n",
      " [  3   3   1   0  12   3   3   0   0   2 218   1]\n",
      " [  7   6   0  13   4   8   1   0   2   3   2 214]]\n",
      "INFO:tensorflow:Step 4400: Validation accuracy = 87.9% (N=3093)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving to \"/notebooks/data/training_atom/speech_commands_train/conv.ckpt-4400\"\n"
     ]
    }
   ],
   "source": [
    "# Training loop.\n",
    "training_steps_max = np.sum(training_steps_list)\n",
    "for training_step in xrange(start_step, training_steps_max + 1):\n",
    "    # Figure out what the current learning rate is.\n",
    "    training_steps_sum = 0\n",
    "    for i in range(len(training_steps_list)):\n",
    "        training_steps_sum += training_steps_list[i]\n",
    "        if training_step <= training_steps_sum:\n",
    "            learning_rate_value = learning_rates_list[i]\n",
    "            break\n",
    "    # Pull the audio samples we'll use for training.\n",
    "    train_fingerprints, train_ground_truth = audio_processor.get_data(\n",
    "        FLAGS.batch_size, 0, model_settings, FLAGS.background_frequency,\n",
    "        FLAGS.background_volume, time_shift_samples, 'training', sess)\n",
    "    # Run the graph with this batch of training data.\n",
    "    train_summary, train_accuracy, cross_entropy_value, _, _ = sess.run(\n",
    "        [\n",
    "            merged_summaries, evaluation_step, cross_entropy_mean, train_step,\n",
    "            increment_global_step\n",
    "        ],\n",
    "        feed_dict={\n",
    "            fingerprint_input: train_fingerprints,\n",
    "            ground_truth_input: train_ground_truth,\n",
    "            learning_rate_input: learning_rate_value,\n",
    "            dropout_prob: 0.5\n",
    "        })\n",
    "    train_writer.add_summary(train_summary, training_step)\n",
    "    if (training_step % 10 == 0):\n",
    "        tf.logging.info('Step #%d: rate %f, accuracy %.1f%%, cross entropy %f' %\n",
    "                        (training_step, learning_rate_value, train_accuracy * 100,\n",
    "                         cross_entropy_value))\n",
    "    is_last_step = (training_step == training_steps_max)\n",
    "    if (training_step % FLAGS.eval_step_interval) == 0 or is_last_step:\n",
    "      set_size = audio_processor.set_size('validation')\n",
    "      total_accuracy = 0\n",
    "      total_conf_matrix = None\n",
    "      for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "        validation_fingerprints, validation_ground_truth = (\n",
    "            audio_processor.get_data(FLAGS.batch_size, i, model_settings, 0.0,\n",
    "                                     0.0, 0, 'validation', sess))\n",
    "        # Run a validation step and capture training summaries for TensorBoard\n",
    "        # with the `merged` op.\n",
    "        validation_summary, validation_accuracy, conf_matrix = sess.run(\n",
    "            [merged_summaries, evaluation_step, confusion_matrix],\n",
    "            feed_dict={\n",
    "                fingerprint_input: validation_fingerprints,\n",
    "                ground_truth_input: validation_ground_truth,\n",
    "                dropout_prob: 1.0\n",
    "            })\n",
    "        validation_writer.add_summary(validation_summary, training_step)\n",
    "        batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "        total_accuracy += (validation_accuracy * batch_size) / set_size\n",
    "        if total_conf_matrix is None:\n",
    "          total_conf_matrix = conf_matrix\n",
    "        else:\n",
    "          total_conf_matrix += conf_matrix\n",
    "      tf.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "      tf.logging.info('Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                      (training_step, total_accuracy * 100, set_size))\n",
    "\n",
    "    # Save the model checkpoint periodically.\n",
    "    if (training_step % FLAGS.save_step_interval == 0 or\n",
    "        training_step == training_steps_max):\n",
    "      checkpoint_path = os.path.join(FLAGS.train_dir,\n",
    "                                     FLAGS.model_architecture + '.ckpt')\n",
    "      tf.logging.info('Saving to \"%s-%d\"', checkpoint_path, training_step)\n",
    "      saver.save(sess, checkpoint_path, global_step=training_step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:set_size=3081\n",
      "INFO:tensorflow:Confusion Matrix:\n",
      " [[257   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1 181   5   3   9   8   6  15   9   0   5  15]\n",
      " [  0   3 241   2   0   0   9   1   0   0   0   0]\n",
      " [  1   7   2 206   1   2   7   0   0   1   7  18]\n",
      " [  1   2   2   0 257   0   1   0   0   4   3   2]\n",
      " [  4   7   1  15   2 207   1   0   0   0   0  16]\n",
      " [  1   4  11   0   4   0 244   2   0   0   1   0]\n",
      " [  2  12   0   0   3   0   3 237   0   1   1   0]\n",
      " [  2   5   0   0   1   0   3   2 227   6   0   0]\n",
      " [  1   3   0   0  20   0   4   1   5 226   2   0]\n",
      " [  0   0   0   0   9   2   0   1   1   0 232   4]\n",
      " [  1   5   1  15   2   3   4   1   0   2   4 213]]\n",
      "INFO:tensorflow:Final test accuracy = 88.5% (N=3081)\n"
     ]
    }
   ],
   "source": [
    "set_size = audio_processor.set_size('testing')\n",
    "tf.logging.info('set_size=%d', set_size)\n",
    "total_accuracy = 0\n",
    "total_conf_matrix = None\n",
    "for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "    test_fingerprints, test_ground_truth = audio_processor.get_data(\n",
    "        FLAGS.batch_size, i, model_settings, 0.0, 0.0, 0, 'testing', sess)\n",
    "    test_accuracy, conf_matrix = sess.run(\n",
    "        [evaluation_step, confusion_matrix],\n",
    "        feed_dict={\n",
    "            fingerprint_input: test_fingerprints,\n",
    "            ground_truth_input: test_ground_truth,\n",
    "            dropout_prob: 1.0\n",
    "        })\n",
    "    batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "    total_accuracy += (test_accuracy * batch_size) / set_size\n",
    "    if total_conf_matrix is None:\n",
    "        total_conf_matrix = conf_matrix\n",
    "    else:\n",
    "        total_conf_matrix += conf_matrix\n",
    "tf.logging.info('Confusion Matrix:\\n %s' % (total_conf_matrix))\n",
    "tf.logging.info('Final test accuracy = %.1f%% (N=%d)' % (total_accuracy * 100,\n",
    "                                                         set_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the trained model to make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/data/test/audio\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# use the model to predict\n",
    "os.chdir (TEST_DIR)\n",
    "print (os.getcwd())\n",
    "\n",
    "file_names = os.listdir(TEST_DIR)\n",
    "#file_names = map(lambda x: TEST_DIR + '/' + x, os.listdir(TEST_DIR))\n",
    "#print (len(file_names))\n",
    "#print (file_names[:10])\n",
    "words_list = input_data.prepare_words_list(FLAGS.wanted_words.split(','))\n",
    "#print (words_list)\n",
    "set_size = len(file_names)\n",
    "subm = zip(file_names, ('silence' for x in range(set_size)))\n",
    "#print (len(subm))\n",
    "#print (subm[:5])\n",
    "\n",
    "# process the audio files\n",
    "batch_num = 0\n",
    "for i in xrange(0, set_size, FLAGS.batch_size):\n",
    "    batch_size = min(FLAGS.batch_size, set_size - i)\n",
    "    batch_filenames = file_names[i:i+batch_size]\n",
    "    predict_fingerprints = audio_processor.get_predicion_data(\n",
    "        batch_filenames, model_settings, sess)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        predicted_indices,\n",
    "        feed_dict={\n",
    "            fingerprint_input: predict_fingerprints,\n",
    "            #ground_truth_input: test_ground_truth,\n",
    "            dropout_prob: 1.0\n",
    "        })\n",
    "    \n",
    "    '''\n",
    "    if batch_num % 100 == 0:\n",
    "        print (\"i {}, batch num {}, batch size = {}\".format(i, batch_num, batch_size))\n",
    "        print (batch_filenames[10:20])\n",
    "        print (test_accuracy[10:20])\n",
    "    '''\n",
    "    for j in range(batch_size):\n",
    "        subm[i+j] = (subm[i+j][0],words_list[test_accuracy[j]])\n",
    "    batch_num += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip_06786ab06.wav\n",
      "_unknown_\n",
      "('clip_3c0b101e0.wav', 'left')\n",
      "clip_a629a0a8c.wav\n",
      "right\n",
      "('clip_24d52f235.wav', 'off')\n",
      "clip_58b5acafb.wav\n",
      "go\n",
      "('clip_47cc3ea4e.wav', '_silence_')\n",
      "clip_c0e7e1556.wav\n",
      "_unknown_\n",
      "('clip_28ce90f4b.wav', '_unknown_')\n",
      "clip_62e2c644e.wav\n",
      "_unknown_\n",
      "('clip_d83092849.wav', '_silence_')\n",
      "clip_0768f2c6f.wav\n",
      "_unknown_\n",
      "('clip_798b8971d.wav', '_unknown_')\n",
      "clip_1a9ad5f94.wav\n",
      "up\n",
      "('clip_9c432a821.wav', 'yes')\n",
      "clip_592bb8eab.wav\n",
      "_unknown_\n",
      "('clip_c2e9fd918.wav', '_unknown_')\n",
      "clip_bb779fa23.wav\n",
      "stop\n",
      "('clip_67a34437e.wav', '_silence_')\n",
      "clip_866c6ffb8.wav\n",
      "_silence_\n",
      "('clip_5ef10de58.wav', 'on')\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,20):\n",
    "    print (batch_filenames[i])\n",
    "    print (words_list[test_accuracy[i]])\n",
    "    print (subm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  0,  0,  9,  1,  0,  8, 10,  8,  2,  1,  7, 11,  1,  1,  1,  4,\n",
       "        1, 10,  0,  9,  1,  0,  1,  1,  6,  8,  8,  1, 11,  0,  9,  2,  6,\n",
       "        0,  4,  6,  1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('clip_55e803b0c.wav', '_unknown_'), ('clip_f248fa402.wav', '_silence_'), ('clip_04476ba6d.wav', '_unknown_'), ('clip_aa853b568.wav', 'off'), ('clip_b8eb354f8.wav', '_unknown_'), ('clip_541afdf9b.wav', '_silence_'), ('clip_04fcbf5e4.wav', 'off'), ('clip_3ec4ed90b.wav', 'yes'), ('clip_4bc631523.wav', '_unknown_'), ('clip_41a2b5699.wav', '_silence_')]\n"
     ]
    }
   ],
   "source": [
    "print (subm[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/data/submission4.csv\n"
     ]
    }
   ],
   "source": [
    "# submission1.csv : sample submission\n",
    "# submission2.csv : TensorFlow example code prediction, trained with Speech Commands Data Set v0.01\n",
    "# submission3.csv : TensorFlow example code prediction, trained with Kaggle Data Set\n",
    "# submission4.csv : TensorFlow example code prediction, trained using AtomOptimizer\n",
    "submission_file_name = DATA_DIR+'/submission4.csv'\n",
    "print (submission_file_name)\n",
    "#np.savetxt(submission_file_name, subm, header='fname,label', comments='')\n",
    "with open(submission_file_name, 'wb') as outfile:\n",
    "    wr = csv.writer(outfile)\n",
    "    wr.writerow(('fname', 'label'))\n",
    "    for i in range(len(subm)):\n",
    "        wr.writerow(subm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='/notebooks/data/submission4.csv' target='_blank'>/notebooks/data/submission4.csv</a><br>"
      ],
      "text/plain": [
       "/notebooks/data/submission4.csv"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
